{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a057990c-ddcf-4daa-8668-39ba947d9064",
   "metadata": {},
   "source": [
    "### Sutter Health\n",
    "\n",
    "We have quite a few of these in our database and I thought it might be instructive to pull some of them.\n",
    "\n",
    "I'm gonna use the (unauthenticated) DoltHub API to get the files. I already manually checked that the files matched the right hospitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64cf755d-8952-499d-9537-531f334ae075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "owner, repo, branch = \"dolthub\", \"standard-charge-files\", \"main\"\n",
    "query = \"\"\"SELECT ccn, doing_business_as_name, standard_charge_file_url FROM hospitals where standard_charge_file_indirect_url = 'https://www.sutterhealth.org/for-patients/healthcare-cost-transparency'\"\"\"\n",
    "res = requests.get(\n",
    "    \"https://www.dolthub.com/api/v1alpha1/{}/{}\".format(owner, repo, branch),\n",
    "    params={\"q\": query},\n",
    "    # headers={ \"authorization\": \"token dhat.v1.99vtt0kv3dl67u552r4d9i2heib0t7jfiergefsd9dp9bl51tls0\" },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf30ab3-3188-4a44-a01d-bcff5a26a154",
   "metadata": {},
   "source": [
    "Let's put these in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f481704-d85d-4906-9c1e-474d7c6bb9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "files = pl.DataFrame(res.json()['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beb07b24-441a-4db3-8857-fb33b47d57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccn</th>\n",
       "      <th>doing_business_as_name</th>\n",
       "      <th>standard_charge_file_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>050766</td>\n",
       "      <td>SUTTER SURGICAL HOSPITAL-NORTH VALLEY</td>\n",
       "      <td>https://www.sutterhealth.org/pdf/chargemaster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>050417</td>\n",
       "      <td></td>\n",
       "      <td>https://www.sutterhealth.org/pdf/chargemaster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>050108</td>\n",
       "      <td>SUTTER MEDICAL CENTER SACRAMENTO</td>\n",
       "      <td>https://www.sutterhealth.org/pdf/chargemaster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>050309</td>\n",
       "      <td>SUTTER ROSEVILLE MEDICAL CENTER</td>\n",
       "      <td>https://www.sutterhealth.org/pdf/chargemaster/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>050047</td>\n",
       "      <td>CALIFORNIA PACIFIC MEDICAL CENTER-VAN NESS CAMPUS</td>\n",
       "      <td>https://www.sutterhealth.org/pdf/chargemaster/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ccn                             doing_business_as_name  \\\n",
       "0  050766              SUTTER SURGICAL HOSPITAL-NORTH VALLEY   \n",
       "1  050417                                                      \n",
       "2  050108                   SUTTER MEDICAL CENTER SACRAMENTO   \n",
       "3  050309                    SUTTER ROSEVILLE MEDICAL CENTER   \n",
       "4  050047  CALIFORNIA PACIFIC MEDICAL CENTER-VAN NESS CAMPUS   \n",
       "\n",
       "                            standard_charge_file_url  \n",
       "0  https://www.sutterhealth.org/pdf/chargemaster/...  \n",
       "1  https://www.sutterhealth.org/pdf/chargemaster/...  \n",
       "2  https://www.sutterhealth.org/pdf/chargemaster/...  \n",
       "3  https://www.sutterhealth.org/pdf/chargemaster/...  \n",
       "4  https://www.sutterhealth.org/pdf/chargemaster/...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.head().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47bbcb-0703-40b6-9df7-b5b51cec0147",
   "metadata": {},
   "source": [
    "Sometimes the last_updated is in the first row of the file.\n",
    "\n",
    "It's always of the form MM-DD-YYYY. It might even be the same for all the files, but I decided to check it in python.\n",
    "\n",
    "I just look through the first columns and rows for a date string. If I find one, I save that as \"last_updated\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5532e656-03dc-424a-89d0-0a7482c661b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_last_updated(df):\n",
    "    \n",
    "    pat = re.compile(r'\\b\\d{1,2}\\/\\d{1,2}\\/\\d{4}\\b')\n",
    "    \n",
    "    # check the column row first\n",
    "    for c in df.columns:\n",
    "        if re.match(pat, c):\n",
    "            mm, dd, yyyy = c.split('/')\n",
    "            last_updated = f'{yyyy}-{mm}-{dd}'\n",
    "            return last_updated\n",
    "        \n",
    "    # check the first few row values\n",
    "    for row in df.rows()[:3]:\n",
    "        for c in row:\n",
    "            if not c:\n",
    "                continue\n",
    "            if re.match(pat, c):\n",
    "                mm, dd, yyyy = c.split('/')\n",
    "                last_updated = f'{yyyy}-{mm}-{dd}'\n",
    "                return last_updated\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42259c4-3ddd-47e1-a3b1-f71e640d20b8",
   "metadata": {},
   "source": [
    "Sometimes there's header metadata. This looks for any time a row contains the header\n",
    "columns, then renames the columns to match that row. Then we slice off the rows that\n",
    "contain the metadata. We limit ourselves to searching the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "471108ca-b052-4717-bef2-1a617768e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_header_row(df):\n",
    "\n",
    "    header_row_cols = ['ID', 'SERVICE_SETTING', 'DESCRIPTION', 'CPT', 'NDC', 'REVENUE_CODE']\n",
    "    \n",
    "    # case: header is correct\n",
    "    if all(c in df.columns for c in header_row_cols):\n",
    "        return df\n",
    "    \n",
    "    # case: header is in a row\n",
    "    for i in range(10):\n",
    "        if all(c in df.to_dicts()[i].values() for c in header_row_cols):\n",
    "            df = df.rename(df.to_dicts()[i])\n",
    "            df = df[i+1:]\n",
    "            return df\n",
    "        else:\n",
    "            print(df[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583922aa-5d17-4809-913c-75ba4f22288b",
   "metadata": {},
   "source": [
    "Rename the cols to fit the unified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5d41dfd-7843-4000-80e0-c823efa11edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = ({\n",
    "    'ID':'internal_code',\n",
    "    'SERVICE_SETTING':'patient_class',\n",
    "    'DESCRIPTION':'description',\n",
    "    'CPT':'hcpcs_cpt',\n",
    "    'NDC':'ndc',\n",
    "    'REVENUE_CODE':'rev_code',\n",
    "})\n",
    "\n",
    "def rename_cols(df):\n",
    "    df = df.rename(rename_dict)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537979a-5a07-41c5-b589-657426635493",
   "metadata": {},
   "source": [
    "The MSDRG and APR-DRG codes are actually hidden in the \"internal_code\" column. So we extract them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "003291af-7194-45d9-ad7a-4d7cbd224f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noncpt(df):\n",
    "    \n",
    "    # APR-DRG part\n",
    "    df_aprdrg = df.with_columns([\n",
    "        pl.col('internal_code').str.extract('APRDRG-(\\d{3}-\\d{1})').alias('code'),\n",
    "        pl.lit('ms-drg').alias('code_prefix'),\n",
    "        pl.col('internal_code').alias('code_orig'),\n",
    "    ]).filter(pl.col('code').is_not_null()).drop('hcpcs_cpt')\n",
    "    \n",
    "    # MS-DRG part\n",
    "    df_msdrg = df.with_columns([\n",
    "        pl.col('internal_code').str.extract('MSDRG-(\\d{3})').alias('code'),\n",
    "        pl.lit('ms-drg').alias('code_prefix'),\n",
    "        pl.col('internal_code').alias('code_orig'),\n",
    "    ]).filter(pl.col('code').is_not_null()).drop('hcpcs_cpt')\n",
    "    \n",
    "    # HCPCS part. Note that there's no code_orig, since we don't extract the code\n",
    "    # from anything\n",
    "    df_hcpcs = df.with_columns([\n",
    "        pl.lit('hcpcs_cpt').alias('code_prefix'),\n",
    "        pl.lit(None).alias('code_orig'),\n",
    "    ]).filter(pl.col('hcpcs_cpt').is_not_null()).rename({'hcpcs_cpt':'code'})\n",
    "    \n",
    "    # In order to stack the dataframes we need to make sure they all have the \n",
    "    # same column order. Pick one column and reoirder\n",
    "    col_order = df_aprdrg.columns\n",
    "    df_msdrg = df_msdrg.select(col_order)\n",
    "    df_hcpcs = df_hcpcs.select(col_order)\n",
    "        \n",
    "    return pl.concat([df_aprdrg, df_msdrg, df_hcpcs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4dc25cd7-3601-4ba8-998d-e1e8d047c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_payers(df):\n",
    "    id_vars = list(rename_dict.values())\n",
    "    value_vars = [c for c in df.columns if c not in id_vars]\n",
    "    variable_name = 'payer_orig'\n",
    "    value_name = 'rate'\n",
    "    df = df.melt(\n",
    "        id_vars, \n",
    "        value_vars,\n",
    "        variable_name,\n",
    "        value_name\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfaef612-2719-47ba-8c0c-0d3b4dcd87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_as_float(df):\n",
    "    df = df.with_columns(\n",
    "        pl.col('rate').str.strip('$').str.strip(' ').str.replace_all(',', '').cast(float)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efd23f5b-43b4-4357-84e8-96c7a17d64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_payer_cat(df):\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col('payer_orig').str.to_lowercase().str.contains('gross ')).then('gross')\n",
    "        .when(pl.col('payer_orig').str.to_lowercase().str.contains('cash ')).then('cash')\n",
    "        .when(pl.col('payer_orig').str.to_lowercase().str.contains('minimum ')).then('min')\n",
    "        .when(pl.col('payer_orig').str.to_lowercase().str.contains('maximum ')).then('max')\n",
    "        .otherwise('payer').alias('payer_category')\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0081368d-3c64-4f50-a18a-94edfe83cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ein(url):\n",
    "    ein = url.split('/')[-1].split('-')[0]\n",
    "    ein_dashed = ein[:2] + '-' + ein[2:]\n",
    "    return ein_dashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7edeab38-f01a-4997-966f-8a2c1205b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filename(url):\n",
    "    return url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0eabe4ee-c6bc-46d0-bf88-d36bf05c655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_payerplan_details(df):\n",
    "    df = df.with_columns([\n",
    "        (\n",
    "            pl.when(pl.col('payer_orig').str.contains('Cigna')).then('Cigna')\n",
    "            .when(pl.col('payer_orig').str.contains('Blue Shield')).then('Blue Shield')\n",
    "            .when(pl.col('payer_orig').str.contains('Aetna')).then('Aetna')\n",
    "            .when(pl.col('payer_orig').str.contains('Health Net')).then('Health Net')\n",
    "            .when(pl.col('payer_orig').str.contains('Humana')).then('Humana')\n",
    "            .when(pl.col('payer_orig').str.contains('Sutter Health Plus')).then('Sutter Health Plus')\n",
    "            .when(pl.col('payer_orig').str.contains('United')).then('United')\n",
    "            .when(pl.col('payer_orig').str.contains('Alignment')).then('Alignment')\n",
    "            .when(pl.col('payer_orig').str.contains('Multiplan')).then('Multiplan')\n",
    "            .otherwise(None)\n",
    "        ).alias('payer_name'),\n",
    "        (\n",
    "            pl.when(pl.col('payer_orig').str.contains('HMO/PPO')).then('hmo ppo')\n",
    "            .when(pl.col('payer_orig').str.contains('HMO / PPO')).then('hmo ppo')\n",
    "            .when(pl.col('payer_orig').str.contains('Medicare Adv_ HMO')).then('medicare_advantage hmo')\n",
    "            .when(pl.col('payer_orig').str.contains('HMO / POS')).then('hmo pos')\n",
    "            .when(pl.col('payer_orig').str.contains('HMO and PPO')).then('hmo ppo')\n",
    "            .when(pl.col('payer_orig').str.contains(' EPO')).then('epo')\n",
    "            .when(pl.col('payer_orig').str.contains(' PPO')).then('ppo')\n",
    "            .when(pl.col('payer_orig').str.contains('Commercial Out of Network - Emergency')).then('oon emergency')\n",
    "            .when(pl.col('payer_orig').str.contains('Commercial Out of Network')).then('oon')\n",
    "            .when(pl.col('payer_orig').str.contains('Commercial')).then('commerical')\n",
    "            .when(pl.col('payer_orig').str.contains('Individual')).then('individual')\n",
    "            .when(pl.col('payer_orig').str.contains('Medi-Cal')).then('medi-cal')\n",
    "            .otherwise(None)\n",
    "        ).alias('plan_name'),\n",
    "    ])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bc425778-6dc1-4492-98fa-071d5c4ca39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [01:30<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for row in tqdm(files.rows()):\n",
    "    \n",
    "    ccn, dba, url = row\n",
    "    \n",
    "    # this one's busted\n",
    "    if ccn == '124001':\n",
    "        continue\n",
    "    \n",
    "    df = pl.read_csv(url, encoding = 'latin-1', null_values = ['NULL'])\n",
    "    \n",
    "    last_updated = df.pipe(find_last_updated)\n",
    "    \n",
    "    df = (df\n",
    "          .pipe(find_header_row)\n",
    "          .pipe(rename_cols)\n",
    "          .pipe(melt_payers)\n",
    "          .filter(pl.col('rate').is_not_null())\n",
    "          .pipe(rate_as_float)\n",
    "          .pipe(get_payer_cat)\n",
    "          .pipe(extract_noncpt)\n",
    "          .pipe(extract_payerplan_details)\n",
    "         )\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col('patient_class').str.to_lowercase(),\n",
    "        pl.col('rev_code').cast(str).str.zfill(4),\n",
    "        pl.lit(ccn).alias('hospital_ccn'),\n",
    "        pl.lit(url).alias('url'),\n",
    "        pl.lit(extract_ein(url)).alias('hospital_ein'),\n",
    "        pl.lit(extract_filename(url)).alias('filename'),\n",
    "        pl.lit(last_updated).alias('file_last_updated').cast(str)\n",
    "    ])\n",
    "    \n",
    "    df = df.unique()\n",
    "    \n",
    "    dfs.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "181d6da8-2be4-4135-a500-b77755ea81ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat(dfs).write_csv('sutter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7c97d-f519-4b0f-a8d1-19861f08a3ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
